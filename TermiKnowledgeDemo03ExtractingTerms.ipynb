{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TermiKnowledgeDemo03ExtractingTerms.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM1LUAZlJ7vghcTcV/eyhlJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/projTermiKnowledge/blob/main/TermiKnowledgeDemo03ExtractingTerms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbUUBKfU_fCO"
      },
      "source": [
        "# This notebook show some methods of terminology extraction\n",
        "\n",
        "1. Installing Part-of-Speech tagger for languages we need:\n",
        "\n",
        "... English...\n",
        "\n",
        "2. Uploading files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK8V1fjv_Qq4"
      },
      "source": [
        "%%bash\n",
        "mkdir treetagger\n",
        "cd treetagger\n",
        "# Download the tagger package for your system (PC-Linux, Mac OS-X, ARM64, ARMHF, ARM-Android, PPC64le-Linux).\n",
        "wget https://cis.lmu.de/~schmid/tools/TreeTagger/data/tree-tagger-linux-3.2.4.tar.gz\n",
        "tar -xzvf tree-tagger-linux-3.2.4.tar.gz\n",
        "# Download the tagging scripts into the same directory.\n",
        "wget https://cis.lmu.de/~schmid/tools/TreeTagger/data/tagger-scripts.tar.gz\n",
        "gunzip tagger-scripts.tar.gz\n",
        "# Download the installation script install-tagger.sh.\n",
        "wget https://cis.lmu.de/~schmid/tools/TreeTagger/data/install-tagger.sh\n",
        "# Download the parameter files for the languages you want to process.\n",
        "# list of all files (parameter files) https://cis.lmu.de/~schmid/tools/TreeTagger/#parfiles\n",
        "wget https://cis.lmu.de/~schmid/tools/TreeTagger/data/english.par.gz\n",
        "sh install-tagger.sh\n",
        "cd ..\n",
        "sudo pip install treetaggerwrapper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDzr0yDrQgo9"
      },
      "source": [
        "%%bash\n",
        "wget https://heibox.uni-heidelberg.de/f/95a3875771c040db959a/?dl=1\n",
        "mv index.html?dl=1 humanrights02.txt\n",
        "\n",
        "wget https://heibox.uni-heidelberg.de/f/a79b829e15c24dbd9e77/?dl=1\n",
        "mv index.html?dl=1 covid3m-en.txt\n",
        "\n",
        "wget https://heibox.uni-heidelberg.de/f/e3c1edbcec9649f5b4c4/?dl=1\n",
        "mv index.html?dl=1 TED2020-enka-en.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsLI0Z_9WwpW"
      },
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/cdf240db84ca4718b718/?dl=1\n",
        "!mv index.html?dl=1 go1984.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-Jt3HaFUgvh"
      },
      "source": [
        "!head --lines=20 humanrights02.txt\n",
        "!wc humanrights02.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCCRAyBFUjGq"
      },
      "source": [
        "!head --lines=20 TED2020-enka-en.txt\n",
        "!wc TED2020-enka-en.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BHfmAw3UlvT"
      },
      "source": [
        "!head --lines=20 covid3m-en.txt\n",
        "!wc covid3m-en.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u15D3DhxUDxF"
      },
      "source": [
        "!./treetagger/cmd/tree-tagger-english humanrights02.txt >humanrights02_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHZtZlIzUFxv"
      },
      "source": [
        "!./treetagger/cmd/tree-tagger-english TED2020-enka-en.txt >TED2020-enka-en_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpAEepWpYh"
      },
      "source": [
        "!./treetagger/cmd/tree-tagger-english go1984.txt >go1984_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3eIf-oWUFKC"
      },
      "source": [
        "!./treetagger/cmd/tree-tagger-english covid3m-en.txt >covid3m-en_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvKMOBGjRpZn"
      },
      "source": [
        "!head --lines=20 humanrights02_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYLJI2lNUTYx"
      },
      "source": [
        "!head --lines=20 TED2020-enka-en_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARuKF3rTUTC0"
      },
      "source": [
        "!head --lines=20 covid3m-en_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHo-Aa0FwaMD"
      },
      "source": [
        "Let's try Brown corpus!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv5a5Dr3wFyc"
      },
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/15f7a67cccb24a0e9eba/?dl=1\n",
        "!mv index.html?dl=1 brownT.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY5g2ztrwcsp"
      },
      "source": [
        "!head --lines=20 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyyZrBSawkAT"
      },
      "source": [
        "!./treetagger/cmd/tree-tagger-english  >"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTTKl96DwsNV"
      },
      "source": [
        "!head --lines=20 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwIlCmmRWKIy"
      },
      "source": [
        "## Python script for term extraction\n",
        "\n",
        "Now we use Part of Speech patterns + frequency information to rank potential candidates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di0L5vaOWJC3"
      },
      "source": [
        "import os, re, sys, time\n",
        "def printDict(DictionaryFrq, FileOut, FileOut1):\n",
        "    for Word, Frq in sorted( DictionaryFrq.items() , key=lambda x: x[1], reverse=True):\n",
        "        if re.search(' ', Word):\n",
        "            FileOut.write(Word + '\\t' + str(Frq) + '\\n')\n",
        "        else:\n",
        "            FileOut1.write(Word + '\\t' + str(Frq) + '\\n')\n",
        "\n",
        "    FileOut.flush()\n",
        "    FileOut1.flush()\n",
        "        \n",
        "\n",
        "\n",
        "def openFiles(SFIn, SFOut, SFOut1):\n",
        "    FInStream = open(SFIn, 'r')\n",
        "    FOutStream = open(SFOut, 'w')\n",
        "    FOutStream1 = open(SFOut1, 'w')\n",
        "    return FInStream, FOutStream, FOutStream1\n",
        "\n",
        "\n",
        "class clProcCorpus(object):\n",
        "    ''' we will read a text file and return a dictionary\n",
        "    this will be done on the line by line basis\n",
        "    The dictionary can be sorted later...\n",
        "    '''\n",
        "    # this is a class for processing a corpus\n",
        "\n",
        "    def __init__(self, FileIN):\n",
        "        self.DictFrq = {}\n",
        "        self.processCorpus(FileIN)\n",
        "\n",
        "    def processCorpus(self, FileIN):\n",
        "        LTerm = []\n",
        "        k = 0\n",
        "        for Line in FileIN:\n",
        "            k+=1\n",
        "            if k%500000 == 0: print(str(k))\n",
        "            Line = Line.strip()\n",
        "            LLine = re.split('\\t', Line)\n",
        "            try:\n",
        "                Word = LLine[0]\n",
        "                PoS = LLine[1]\n",
        "                Lemma = LLine[2]\n",
        "            except:\n",
        "                Word = \"\"\n",
        "                PoS = \"\"\n",
        "                Lemma = \"\"\n",
        "            \n",
        "      #Select the Tags for your langauge\n",
        "            #if re.match('N.*', PoS) or re.match('A.*', PoS): #Arm\n",
        "            #if re.match('N.*', PoS) or re.match('ADJ.*', PoS): #DE\n",
        "            if re.match('N.*', PoS) or re.match('J.*', PoS): #EN\n",
        "\n",
        "      #Terms as Words or Lemmas\n",
        "                LTerm.append(Word)\n",
        "                # LTerm.append(Lemma)\n",
        "            else:\n",
        "                STerm = ' '.join(LTerm)\n",
        "                LTerm = []\n",
        "\n",
        "                try:\n",
        "                    self.DictFrq[STerm] += 1\n",
        "                except:\n",
        "                    self.DictFrq[STerm] = 1        \n",
        "\n",
        "        return\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlI14bN2YVkb"
      },
      "source": [
        "FIn, FOut, FOut1 = openFiles('humanrights02_vert.txt', 'humanrights02_terms.txt', 'humanrights02_terms1.txt')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vibySFQlcG2N"
      },
      "source": [
        "FIn, FOut, FOut1 = openFiles('covid3m-en_vert.txt', 'covid3m-en_terms.txt', 'covid3m-en_terms1.txt')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeMoezehcHhf"
      },
      "source": [
        "FIn, FOut, FOut1 = openFiles('TED2020-enka-en_vert.txt', 'TED2020-enka-en_terms.txt', 'TED2020-enka-en_terms1.txt')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YREIWIUPcIHm"
      },
      "source": [
        "# try it out yourself on your files\n",
        "# upload a file from your computer, then PoS-tag it\n",
        "!./treetagger/cmd/tree-tagger-english  > \n",
        "# FIn, FOut, FOut1 = openFiles('', '', '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS2HQqWLZiUT",
        "outputId": "1646c881-f1f2-470c-c096-acd7699fe1f7"
      },
      "source": [
        "OCorpus = clProcCorpus(FIn)\n",
        "printDict(OCorpus.DictFrq, FOut, FOut1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500000\n"
          ]
        }
      ]
    }
  ]
}